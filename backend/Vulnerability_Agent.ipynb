{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Software Vulnerability Assessment Agent\n",
    "\n",
    "**Task:** Transform the Red Team agent concept into a comprehensive software vulnerability scanner that can analyze your codebase for security weaknesses.\n",
    "\n",
    "> **Key Insight:** Instead of just testing LLM prompt injection, we'll create an AI-powered security audit tool that can identify common software vulnerabilities based on OWASP Top 10, CWE (Common Weakness Enumeration), and security best practices.\n",
    "\n",
    "**What We'll Check For:**\n",
    "- **Injection Vulnerabilities**: SQL injection, command injection, LDAP injection\n",
    "- **Authentication & Authorization Flaws**: Weak password policies, insecure session management\n",
    "- **Sensitive Data Exposure**: Hardcoded secrets, unencrypted data storage\n",
    "- **XML External Entities (XXE)**: Unsafe XML parsing\n",
    "- **Broken Access Control**: Missing authorization checks\n",
    "- **Security Misconfiguration**: Default credentials, verbose error messages\n",
    "- **Cross-Site Scripting (XSS)**: Reflected, stored, and DOM-based XSS\n",
    "- **Insecure Deserialization**: Unsafe object deserialization\n",
    "- **Using Components with Known Vulnerabilities**: Outdated dependencies\n",
    "- **Insufficient Logging & Monitoring**: Missing security event logging\n",
    "\n",
    "**Instructions:**\n",
    "1. Create a vulnerability assessment agent that can analyze Python code files\n",
    "2. Generate specific test cases and scanning patterns for each vulnerability type\n",
    "3. Scan the actual codebase files in the workspace\n",
    "4. Provide detailed reports with severity levels and remediation suggestions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-03 10:35:56,704 ag_aisoftdev.utils WARNING Optional core dependencies not found. Some features will be degraded. provider=None model=None latency_ms=None artifacts_path=None\n",
      "2025-10-03 10:35:56,705 ag_aisoftdev.utils WARNING To enable full functionality run: pip install python-dotenv ipython plantuml provider=None model=None latency_ms=None artifacts_path=None\n",
      "2025-10-03 10:35:56,705 ag_aisoftdev.utils WARNING To enable full functionality run: pip install python-dotenv ipython plantuml provider=None model=None latency_ms=None artifacts_path=None\n",
      "2025-10-03 10:35:56,713 ag_aisoftdev.utils WARNING 'requests' package not installed; HTTP helpers are disabled. provider=None model=None latency_ms=None artifacts_path=None\n",
      "2025-10-03 10:35:56,713 ag_aisoftdev.utils WARNING 'requests' package not installed; HTTP helpers are disabled. provider=None model=None latency_ms=None artifacts_path=None\n",
      "2025-10-03 10:35:56,722 ag_aisoftdev.utils WARNING python-dotenv not installed; .env will not be loaded. provider=None model=None latency_ms=None artifacts_path=None\n",
      "2025-10-03 10:35:56,724 ag_aisoftdev.utils ERROR No module named 'openai' provider=openai model=gpt-4o latency_ms=None artifacts_path=None\n",
      "2025-10-03 10:35:56,722 ag_aisoftdev.utils WARNING python-dotenv not installed; .env will not be loaded. provider=None model=None latency_ms=None artifacts_path=None\n",
      "2025-10-03 10:35:56,724 ag_aisoftdev.utils ERROR No module named 'openai' provider=openai model=gpt-4o latency_ms=None artifacts_path=None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utils path exists: True\n",
      "Project root: c:\\Users\\labadmin\\Documents\\repo\\KMSH_contracting\n",
      "Successfully imported utils functions!\n",
      "‚ö†Ô∏è LLM client initialization returned None values\n",
      "‚ö†Ô∏è LLM setup failed: Client initialization failed\n",
      "Using fallback configuration - AI analysis will be disabled\n",
      "Final configuration: client=False, model=gpt-4o, provider=openai\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the project's root directory to the Python path to ensure 'utils' can be imported.\n",
    "try:\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "except IndexError:\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd()))\n",
    "\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "# Verify the utils directory exists\n",
    "utils_path = os.path.join(project_root, 'utils')\n",
    "print(f\"Utils path exists: {os.path.exists(utils_path)}\")\n",
    "print(f\"Project root: {project_root}\")\n",
    "\n",
    "# Try to import utils and setup LLM client\n",
    "client, model_name, api_provider = None, None, None\n",
    "\n",
    "try:\n",
    "    from utils import setup_llm_client, get_completion, save_artifact, load_artifact, clean_llm_output\n",
    "    print(\"Successfully imported utils functions!\")\n",
    "    \n",
    "    # Setup the LLM client\n",
    "    try:\n",
    "        client, model_name, api_provider = setup_llm_client(model_name=\"gpt-4o\")\n",
    "        if client and model_name and api_provider:\n",
    "            print(f\"‚úÖ LLM client initialized: {model_name} via {api_provider}\")\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è LLM client initialization returned None values\")\n",
    "            raise Exception(\"Client initialization failed\")\n",
    "    except Exception as llm_error:\n",
    "        print(f\"‚ö†Ô∏è LLM setup failed: {llm_error}\")\n",
    "        client, model_name, api_provider = None, \"gpt-4o\", \"openai\"\n",
    "        print(\"Using fallback configuration - AI analysis will be disabled\")\n",
    "    \n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Import error: {e}\")\n",
    "    print(f\"sys.path: {sys.path}\")\n",
    "    \n",
    "    # Create fallback functions\n",
    "    def get_completion(prompt, client, model, provider):\n",
    "        \"\"\"Dummy function - AI analysis will be skipped\"\"\"\n",
    "        return '{\"vulnerabilities_found\": [], \"overall_security_score\": \"5\", \"summary\": \"AI analysis not available - missing LLM setup\"}'\n",
    "    \n",
    "    def save_artifact(content, path, overwrite=False):\n",
    "        \"\"\"Dummy save function\"\"\"\n",
    "        print(f\"Would save to: {path}\")\n",
    "        return True\n",
    "    \n",
    "    def load_artifact(path):\n",
    "        \"\"\"Dummy load function\"\"\"\n",
    "        print(f\"Would load from: {path}\")\n",
    "        return None\n",
    "    \n",
    "    def clean_llm_output(content, language='python'):\n",
    "        \"\"\"Dummy clean function\"\"\"\n",
    "        return content\n",
    "    \n",
    "    client, model_name, api_provider = None, \"gpt-4o\", \"openai\"\n",
    "    print(\"Using basic fallback configuration - AI features disabled\")\n",
    "\n",
    "print(f\"Final configuration: client={client is not None}, model={model_name}, provider={api_provider}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative: Basic setup without utils (if utils import fails)\n",
    "# Uncomment and use this if the above setup doesn't work\n",
    "\n",
    "# client = None\n",
    "# model_name = \"gpt-4o\" \n",
    "# api_provider = \"openai\"\n",
    "# project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "\n",
    "# def get_completion(prompt, client, model, provider):\n",
    "#     \"\"\"Dummy function - AI analysis will be skipped\"\"\"\n",
    "#     return '{\"vulnerabilities_found\": [], \"overall_security_score\": \"5\", \"summary\": \"AI analysis not available\"}'\n",
    "\n",
    "# print(\"Using basic setup - AI analysis features will be limited\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Pattern-based scanning only: AI analysis DISABLED\n",
      "‚úÖ Software Vulnerability Scanner initialized!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Tuple\n",
    "import json\n",
    "\n",
    "# Software Vulnerability Assessment Agent\n",
    "class SoftwareVulnerabilityScanner:\n",
    "    def __init__(self, client, model_name, api_provider):\n",
    "        self.client = client\n",
    "        self.model_name = model_name\n",
    "        self.api_provider = api_provider\n",
    "        self.ai_enabled = client is not None and 'get_completion' in globals()\n",
    "        \n",
    "        if self.ai_enabled:\n",
    "            print(\"ü§ñ AI-powered analysis: ENABLED\")\n",
    "        else:\n",
    "            print(\"üîç Pattern-based scanning only: AI analysis DISABLED\")\n",
    "        \n",
    "        # Define vulnerability patterns and their severity levels\n",
    "        self.vulnerability_patterns = {\n",
    "            \"sql_injection\": {\n",
    "                \"patterns\": [\n",
    "                    r\"execute\\s*\\(\\s*[\\\"'][^\\\"']*\\+.*[\\\"']\\s*\\)\",\n",
    "                    r\"cursor\\.execute\\s*\\(\\s*[\\\"'][^\\\"']*%.*[\\\"']\\s*%\",\n",
    "                    r\"\\.format\\s*\\([^)]*\\)\\s*\\)\",\n",
    "                    r\"f[\\\"'][^\\\"']*\\{[^}]*\\}[^\\\"']*[\\\"']\"\n",
    "                ],\n",
    "                \"severity\": \"HIGH\",\n",
    "                \"description\": \"Potential SQL Injection vulnerability\"\n",
    "            },\n",
    "            \"hardcoded_secrets\": {\n",
    "                \"patterns\": [\n",
    "                    r\"password\\s*=\\s*[\\\"'][^\\\"']{8,}[\\\"']\",\n",
    "                    r\"api_key\\s*=\\s*[\\\"'][^\\\"']{20,}[\\\"']\",\n",
    "                    r\"secret\\s*=\\s*[\\\"'][^\\\"']{10,}[\\\"']\",\n",
    "                    r\"token\\s*=\\s*[\\\"'][^\\\"']{20,}[\\\"']\"\n",
    "                ],\n",
    "                \"severity\": \"CRITICAL\",\n",
    "                \"description\": \"Hardcoded secrets or credentials found\"\n",
    "            },\n",
    "            \"command_injection\": {\n",
    "                \"patterns\": [\n",
    "                    r\"os\\.system\\s*\\([^)]*\\+\",\n",
    "                    r\"subprocess\\.(call|run|Popen)\\s*\\([^)]*\\+\",\n",
    "                    r\"eval\\s*\\(\",\n",
    "                    r\"exec\\s*\\(\"\n",
    "                ],\n",
    "                \"severity\": \"HIGH\",\n",
    "                \"description\": \"Potential command injection vulnerability\"\n",
    "            },\n",
    "            \"insecure_random\": {\n",
    "                \"patterns\": [\n",
    "                    r\"random\\.random\\(\\)\",\n",
    "                    r\"random\\.randint\\(\",\n",
    "                    r\"random\\.choice\\(\"\n",
    "                ],\n",
    "                \"severity\": \"MEDIUM\",\n",
    "                \"description\": \"Use of insecure random number generator for security purposes\"\n",
    "            },\n",
    "            \"weak_crypto\": {\n",
    "                \"patterns\": [\n",
    "                    r\"hashlib\\.md5\\(\",\n",
    "                    r\"hashlib\\.sha1\\(\",\n",
    "                    r\"DES\\.\",\n",
    "                    r\"RC4\\.\"\n",
    "                ],\n",
    "                \"severity\": \"MEDIUM\",\n",
    "                \"description\": \"Use of weak cryptographic algorithms\"\n",
    "            },\n",
    "            \"debug_mode\": {\n",
    "                \"patterns\": [\n",
    "                    r\"debug\\s*=\\s*True\",\n",
    "                    r\"DEBUG\\s*=\\s*True\",\n",
    "                    r\"app\\.debug\\s*=\\s*True\"\n",
    "                ],\n",
    "                \"severity\": \"MEDIUM\",\n",
    "                \"description\": \"Debug mode enabled - may expose sensitive information\"\n",
    "            },\n",
    "            \"unsafe_pickle\": {\n",
    "                \"patterns\": [\n",
    "                    r\"pickle\\.loads?\\s*\\(\",\n",
    "                    r\"cPickle\\.loads?\\s*\\(\"\n",
    "                ],\n",
    "                \"severity\": \"HIGH\",\n",
    "                \"description\": \"Unsafe deserialization with pickle - can lead to code execution\"\n",
    "            }\n",
    "        }\n",
    "\n",
    "    def scan_file(self, file_path: str) -> List[Dict]:\n",
    "        \"\"\"Scan a single file for vulnerabilities\"\"\"\n",
    "        vulnerabilities = []\n",
    "        \n",
    "        try:\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                content = f.read()\n",
    "                lines = content.split('\\n')\n",
    "                \n",
    "            for vuln_type, config in self.vulnerability_patterns.items():\n",
    "                for pattern in config['patterns']:\n",
    "                    matches = re.finditer(pattern, content, re.IGNORECASE)\n",
    "                    for match in matches:\n",
    "                        # Find line number\n",
    "                        line_num = content[:match.start()].count('\\n') + 1\n",
    "                        line_content = lines[line_num - 1].strip()\n",
    "                        \n",
    "                        vulnerabilities.append({\n",
    "                            'type': vuln_type,\n",
    "                            'severity': config['severity'],\n",
    "                            'description': config['description'],\n",
    "                            'file': file_path,\n",
    "                            'line': line_num,\n",
    "                            'code': line_content,\n",
    "                            'match': match.group()\n",
    "                        })\n",
    "        except Exception as e:\n",
    "            print(f\"Error scanning {file_path}: {e}\")\n",
    "            \n",
    "        return vulnerabilities\n",
    "\n",
    "    def ai_code_review(self, file_path: str, code_snippet: str) -> Dict:\n",
    "        \"\"\"Use AI to perform deeper security analysis\"\"\"\n",
    "        if not self.ai_enabled:\n",
    "            return {\"vulnerabilities_found\": [], \"overall_security_score\": \"5\", \"summary\": \"AI analysis disabled\"}\n",
    "            \n",
    "        prompt = f\"\"\"\n",
    "        You are a cybersecurity expert conducting a security code review. Analyze the following Python code for security vulnerabilities.\n",
    "\n",
    "        File: {file_path}\n",
    "        Code:\n",
    "        ```python\n",
    "        {code_snippet}\n",
    "        ```\n",
    "\n",
    "        Look for:\n",
    "        1. Injection vulnerabilities (SQL, command, LDAP)\n",
    "        2. Authentication and authorization flaws\n",
    "        3. Sensitive data exposure\n",
    "        4. Security misconfigurations\n",
    "        5. Input validation issues\n",
    "        6. Cryptographic weaknesses\n",
    "        7. Error handling that reveals sensitive information\n",
    "\n",
    "        Respond with a JSON object containing:\n",
    "        {{\n",
    "            \"vulnerabilities_found\": [\n",
    "                {{\n",
    "                    \"type\": \"vulnerability_type\",\n",
    "                    \"severity\": \"CRITICAL|HIGH|MEDIUM|LOW\",\n",
    "                    \"description\": \"detailed description\",\n",
    "                    \"line_numbers\": [1, 2, 3],\n",
    "                    \"recommendation\": \"how to fix this issue\"\n",
    "                }}\n",
    "            ],\n",
    "            \"overall_security_score\": \"1-10 where 10 is most secure\",\n",
    "            \"summary\": \"brief security assessment summary\"\n",
    "        }}\n",
    "        \"\"\"\n",
    "        \n",
    "        try:\n",
    "            response = get_completion(prompt, self.client, self.model_name, self.api_provider)\n",
    "            # Extract JSON from response\n",
    "            json_match = re.search(r'\\{.*\\}', response, re.DOTALL)\n",
    "            if json_match:\n",
    "                return json.loads(json_match.group(0))\n",
    "        except Exception as e:\n",
    "            print(f\"AI analysis error: {e}\")\n",
    "            \n",
    "        return {\"vulnerabilities_found\": [], \"overall_security_score\": \"0\", \"summary\": \"Analysis failed\"}\n",
    "\n",
    "    def scan_codebase(self, directory: str = None) -> Dict:\n",
    "        \"\"\"Scan entire codebase for vulnerabilities\"\"\"\n",
    "        if directory is None:\n",
    "            directory = project_root\n",
    "            \n",
    "        results = {\n",
    "            \"scanned_files\": 0,\n",
    "            \"total_vulnerabilities\": 0,\n",
    "            \"vulnerabilities_by_severity\": {\"CRITICAL\": 0, \"HIGH\": 0, \"MEDIUM\": 0, \"LOW\": 0},\n",
    "            \"detailed_findings\": []\n",
    "        }\n",
    "        \n",
    "        print(f\"üîç Scanning directory: {directory}\")\n",
    "        \n",
    "        # Scan Python files\n",
    "        for py_file in Path(directory).rglob(\"*.py\"):\n",
    "            if \"test\" in str(py_file).lower() or \"__pycache__\" in str(py_file):\n",
    "                continue\n",
    "                \n",
    "            results[\"scanned_files\"] += 1\n",
    "            print(f\"  üìÑ Scanning: {os.path.basename(py_file)}\")\n",
    "            file_vulns = self.scan_file(str(py_file))\n",
    "            \n",
    "            # Add AI-powered analysis for files with initial findings (only if AI is enabled)\n",
    "            if file_vulns and self.ai_enabled:\n",
    "                try:\n",
    "                    with open(py_file, 'r', encoding='utf-8') as f:\n",
    "                        code_content = f.read()\n",
    "                    \n",
    "                    # Limit code size for AI analysis\n",
    "                    if len(code_content) < 5000:  # Only analyze smaller files\n",
    "                        print(f\"    ü§ñ Running AI analysis on {os.path.basename(py_file)}...\")\n",
    "                        ai_analysis = self.ai_code_review(str(py_file), code_content)\n",
    "                        \n",
    "                        # Merge AI findings\n",
    "                        for ai_vuln in ai_analysis.get(\"vulnerabilities_found\", []):\n",
    "                            file_vulns.append({\n",
    "                                'type': f\"ai_detected_{ai_vuln['type']}\",\n",
    "                                'severity': ai_vuln['severity'],\n",
    "                                'description': ai_vuln['description'],\n",
    "                                'file': str(py_file),\n",
    "                                'line': ai_vuln.get('line_numbers', [0])[0],\n",
    "                                'code': 'AI-detected vulnerability',\n",
    "                                'recommendation': ai_vuln.get('recommendation', 'No recommendation provided')\n",
    "                            })\n",
    "                except Exception as e:\n",
    "                    print(f\"    ‚ùå AI analysis failed for {py_file}: {e}\")\n",
    "            \n",
    "            for vuln in file_vulns:\n",
    "                results[\"total_vulnerabilities\"] += 1\n",
    "                results[\"vulnerabilities_by_severity\"][vuln[\"severity\"]] += 1\n",
    "                results[\"detailed_findings\"].append(vuln)\n",
    "        \n",
    "        return results\n",
    "\n",
    "# Check if we have the required variables\n",
    "missing_vars = []\n",
    "for var_name in ['client', 'model_name', 'api_provider']:\n",
    "    if var_name not in globals():\n",
    "        missing_vars.append(var_name)\n",
    "\n",
    "if missing_vars:\n",
    "    print(f\"‚ö†Ô∏è  Missing variables: {missing_vars}\")\n",
    "    print(\"Using default values...\")\n",
    "    if 'client' not in globals():\n",
    "        client = None\n",
    "    if 'model_name' not in globals():\n",
    "        model_name = \"gpt-4o\"\n",
    "    if 'api_provider' not in globals():\n",
    "        api_provider = \"openai\"\n",
    "\n",
    "# Initialize the vulnerability scanner\n",
    "vuln_scanner = SoftwareVulnerabilityScanner(client, model_name, api_provider)\n",
    "print(\"‚úÖ Software Vulnerability Scanner initialized!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Starting comprehensive software vulnerability assessment...\n",
      "============================================================\n",
      "Scanning directory: c:\\Users\\labadmin\\Documents\\repo\\KMSH_contracting\\utils\n",
      "Directory exists: True\n",
      "üîç Scanning directory: c:\\Users\\labadmin\\Documents\\repo\\KMSH_contracting\\utils\n",
      "  üìÑ Scanning: artifacts.py\n",
      "  üìÑ Scanning: audio.py\n",
      "  üìÑ Scanning: errors.py\n",
      "  üìÑ Scanning: helpers.py\n",
      "  üìÑ Scanning: http.py\n",
      "  üìÑ Scanning: image_gen.py\n",
      "  üìÑ Scanning: llm.py\n",
      "  üìÑ Scanning: logging.py\n",
      "  üìÑ Scanning: models.py\n",
      "  üìÑ Scanning: plantuml.py\n",
      "  üìÑ Scanning: rate_limit.py\n",
      "  üìÑ Scanning: settings.py\n",
      "  üìÑ Scanning: __init__.py\n",
      "  üìÑ Scanning: anthropic.py\n",
      "  üìÑ Scanning: base.py\n",
      "  üìÑ Scanning: google.py\n",
      "  üìÑ Scanning: huggingface.py\n",
      "  üìÑ Scanning: openai.py\n",
      "  üìÑ Scanning: __init__.py\n",
      "üìä SCAN SUMMARY\n",
      "Files scanned: 19\n",
      "Total vulnerabilities found: 31\n",
      "\n",
      "üö® VULNERABILITIES BY SEVERITY:\n",
      "  HIGH: 31\n",
      "\n",
      "============================================================\n",
      "üìã DETAILED FINDINGS:\n",
      "============================================================\n",
      "\n",
      "üìÅ FILE: artifacts.py\n",
      "----------------------------------------\n",
      "1. üü† HIGH - SQL_INJECTION\n",
      "   üìç Line 138: Potential SQL Injection vulnerability\n",
      "   üìù Code: raise ArtifactNotFoundError(f\"Artifact not found: {final}\")\n",
      "\n",
      "2. üü† HIGH - SQL_INJECTION\n",
      "   üìç Line 170: Potential SQL Injection vulnerability\n",
      "   üìù Code: f\"Artifact already exists: {path}. Pass overwrite=True to replace.\"\n",
      "\n",
      "3. üü† HIGH - SQL_INJECTION\n",
      "   üìç Line 195: Potential SQL Injection vulnerability\n",
      "   üìù Code: f\"Unsupported content type: {type(content)!r}\"\n",
      "\n",
      "\n",
      "üìÅ FILE: audio.py\n",
      "----------------------------------------\n",
      "1. üü† HIGH - SQL_INJECTION\n",
      "   üìç Line 34: Potential SQL Injection vulnerability\n",
      "   üìù Code: f\"Audio file not found at {audio_path}\",\n",
      "\n",
      "2. üü† HIGH - SQL_INJECTION\n",
      "   üìç Line 63: Potential SQL Injection vulnerability\n",
      "   üìù Code: f\"Audio file not found at {audio_path}\",\n",
      "\n",
      "\n",
      "üìÅ FILE: errors.py\n",
      "----------------------------------------\n",
      "1. üü† HIGH - SQL_INJECTION\n",
      "   üìç Line 37: Potential SQL Injection vulnerability\n",
      "   üìù Code: super().__init__(f\"[{provider}:{model}] {operation} error: {message}\")\n",
      "\n",
      "\n",
      "üìÅ FILE: image_gen.py\n",
      "----------------------------------------\n",
      "1. üü† HIGH - SQL_INJECTION\n",
      "   üìç Line 19: Potential SQL Injection vulnerability\n",
      "   üìù Code: filename = f\"image_{int(time.time())}{ext}\"\n",
      "\n",
      "2. üü† HIGH - SQL_INJECTION\n",
      "   üìç Line 23: Potential SQL Injection vulnerability\n",
      "   üìù Code: image_url = f\"data:{image_mime};base64,{image_data_base64}\"\n",
      "\n",
      "\n",
      "üìÅ FILE: llm.py\n",
      "----------------------------------------\n",
      "1. üü† HIGH - SQL_INJECTION\n",
      "   üìç Line 494: Potential SQL Injection vulnerability\n",
      "   üìù Code: f\"Original input: {user_input}\"\n",
      "\n",
      "2. üü† HIGH - SQL_INJECTION\n",
      "   üìç Line 505: Potential SQL Injection vulnerability\n",
      "   üìù Code: f\"actual_model: {actual_model}, provider: {provider}. \"\n",
      "\n",
      "3. üü† HIGH - SQL_INJECTION\n",
      "   üìç Line 506: Potential SQL Injection vulnerability\n",
      "   üìù Code: f\"Original input: {user_input}\"\n",
      "\n",
      "4. üü† HIGH - SQL_INJECTION\n",
      "   üìç Line 525: Potential SQL Injection vulnerability\n",
      "   üìù Code: f\"{e}. Original input: {user_input}\",\n",
      "\n",
      "\n",
      "üìÅ FILE: models.py\n",
      "----------------------------------------\n",
      "1. üü† HIGH - SQL_INJECTION\n",
      "   üìç Line 115: Potential SQL Injection vulnerability\n",
      "   üìù Code: return f\"{int(x):,}\"\n",
      "\n",
      "2. üü† HIGH - SQL_INJECTION\n",
      "   üìç Line 120: Potential SQL Injection vulnerability\n",
      "   üìù Code: f\"| {model_name} | {model_provider or '-'} | {'‚úÖ' if model_text else '‚ùå'} | \"\n",
      "\n",
      "3. üü† HIGH - SQL_INJECTION\n",
      "   üìç Line 121: Potential SQL Injection vulnerability\n",
      "   üìù Code: f\"{'‚úÖ' if model_vision else '‚ùå'} | {'‚úÖ' if model_image else '‚ùå'} | \"\n",
      "\n",
      "4. üü† HIGH - SQL_INJECTION\n",
      "   üìç Line 122: Potential SQL Injection vulnerability\n",
      "   üìù Code: f\"{'‚úÖ' if model_image_mod else '‚ùå'} | {'‚úÖ' if model_audio else '‚ùå'} | \"\n",
      "\n",
      "5. üü† HIGH - SQL_INJECTION\n",
      "   üìç Line 123: Potential SQL Injection vulnerability\n",
      "   üìù Code: f\"{_fmt_num(context)} | {_fmt_num(max_tokens)} |\"\n",
      "\n",
      "\n",
      "üìÅ FILE: plantuml.py\n",
      "----------------------------------------\n",
      "1. üü† HIGH - SQL_INJECTION\n",
      "   üìç Line 61: Potential SQL Injection vulnerability\n",
      "   üìù Code: raise ArtifactError(f\"PlantUML rendering failed: {exc}\") from exc\n",
      "\n",
      "2. üü† HIGH - SQL_INJECTION\n",
      "   üìç Line 69: Potential SQL Injection vulnerability\n",
      "   üìù Code: raise ArtifactError(f\"PlantUML rendering failed: {exc}\") from exc\n",
      "\n",
      "3. üü† HIGH - SQL_INJECTION\n",
      "   üìç Line 76: Potential SQL Injection vulnerability\n",
      "   üìù Code: detail = \"; \".join(f\"{label}: {err}\" for label, err in attempts)\n",
      "\n",
      "4. üü† HIGH - SQL_INJECTION\n",
      "   üìç Line 77: Potential SQL Injection vulnerability\n",
      "   üìù Code: message = f\"PlantUML rendering failed after attempts [{detail}]: {exc}\"\n",
      "\n",
      "5. üü† HIGH - SQL_INJECTION\n",
      "   üìç Line 79: Potential SQL Injection vulnerability\n",
      "   üìù Code: message = f\"PlantUML rendering failed: {exc}\"\n",
      "\n",
      "\n",
      "üìÅ FILE: rate_limit.py\n",
      "----------------------------------------\n",
      "1. üü† HIGH - SQL_INJECTION\n",
      "   üìç Line 38: Potential SQL Injection vulnerability\n",
      "   üìù Code: env = f\"UTILS_RATE_LIMIT_QPS_{provider.upper()}\"\n",
      "\n",
      "2. üü† HIGH - SQL_INJECTION\n",
      "   üìç Line 54: Potential SQL Injection vulnerability\n",
      "   üìù Code: key = f\"{provider}:{api_key}:{model_name}\"\n",
      "\n",
      "\n",
      "üìÅ FILE: anthropic.py\n",
      "----------------------------------------\n",
      "1. üü† HIGH - SQL_INJECTION\n",
      "   üìç Line 93: Potential SQL Injection vulnerability\n",
      "   üìù Code: f\"Could not load image from {image_path_or_url}\"\n",
      "\n",
      "\n",
      "üìÅ FILE: google.py\n",
      "----------------------------------------\n",
      "1. üü† HIGH - SQL_INJECTION\n",
      "   üìç Line 158: Potential SQL Injection vulnerability\n",
      "   üìù Code: \"google\", model_name, \"image_generation\", f\"API call failed: {e}\"\n",
      "\n",
      "2. üü† HIGH - SQL_INJECTION\n",
      "   üìç Line 293: Potential SQL Injection vulnerability\n",
      "   üìù Code: f\"Could not load image from {image_path_or_url}\"\n",
      "\n",
      "3. üü† HIGH - SQL_INJECTION\n",
      "   üìç Line 334: Potential SQL Injection vulnerability\n",
      "   üìù Code: \"google\", model_name, \"vision_completion\", f\"API call failed: {e}\"\n",
      "\n",
      "4. üü† HIGH - SQL_INJECTION\n",
      "   üìç Line 422: Potential SQL Injection vulnerability\n",
      "   üìù Code: \"google\", model_name, \"image_edit\", f\"Edit failed: {e}\"\n",
      "\n",
      "\n",
      "üìÅ FILE: openai.py\n",
      "----------------------------------------\n",
      "1. üü† HIGH - SQL_INJECTION\n",
      "   üìç Line 201: Potential SQL Injection vulnerability\n",
      "   üìù Code: image_url = f\"data:{mime_type};base64,{image_base64}\"\n",
      "\n",
      "2. üü† HIGH - SQL_INJECTION\n",
      "   üìç Line 268: Potential SQL Injection vulnerability\n",
      "   üìù Code: image_url = f\"data:{mime_type};base64,{image_base64}\"\n",
      "\n",
      "============================================================\n",
      "üéØ SECURITY RECOMMENDATIONS:\n",
      "============================================================\n",
      "\n",
      "üîí IMMEDIATE ACTIONS REQUIRED:\n",
      "1. Address all CRITICAL vulnerabilities immediately\n",
      "2. Review and fix HIGH severity issues within 24-48 hours\n",
      "3. Plan remediation for MEDIUM severity issues\n",
      "4. Consider LOW severity issues for future security hardening\n",
      "\n",
      "üõ°Ô∏è SECURITY BEST PRACTICES:\n",
      "1. Use parameterized queries to prevent SQL injection\n",
      "2. Store secrets in environment variables, not hardcoded\n",
      "3. Use secure random generators from the 'secrets' module\n",
      "4. Implement proper input validation and sanitization\n",
      "5. Use strong cryptographic algorithms (SHA-256, AES-256)\n",
      "6. Add security headers and proper error handling\n",
      "7. Implement comprehensive logging for security events\n",
      "\n",
      "\n",
      "============================================================\n",
      "‚úÖ Vulnerability assessment complete!\n"
     ]
    }
   ],
   "source": [
    "# Run the comprehensive vulnerability scan\n",
    "print(\"üîç Starting comprehensive software vulnerability assessment...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Ensure project_root is defined (in case setup cell wasn't run properly)\n",
    "if 'project_root' not in globals():\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "    print(f\"Setting project_root to: {project_root}\")\n",
    "\n",
    "# Scan the utils directory (where most of the Python code is)\n",
    "utils_dir = os.path.join(project_root, \"utils\")\n",
    "print(f\"Scanning directory: {utils_dir}\")\n",
    "print(f\"Directory exists: {os.path.exists(utils_dir)}\")\n",
    "\n",
    "scan_results = vuln_scanner.scan_codebase(utils_dir)\n",
    "\n",
    "print(f\"üìä SCAN SUMMARY\")\n",
    "print(f\"Files scanned: {scan_results['scanned_files']}\")\n",
    "print(f\"Total vulnerabilities found: {scan_results['total_vulnerabilities']}\")\n",
    "print(\"\\nüö® VULNERABILITIES BY SEVERITY:\")\n",
    "for severity, count in scan_results['vulnerabilities_by_severity'].items():\n",
    "    if count > 0:\n",
    "        print(f\"  {severity}: {count}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üìã DETAILED FINDINGS:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Group findings by file for better readability\n",
    "findings_by_file = {}\n",
    "for finding in scan_results['detailed_findings']:\n",
    "    file_path = finding['file']\n",
    "    if file_path not in findings_by_file:\n",
    "        findings_by_file[file_path] = []\n",
    "    findings_by_file[file_path].append(finding)\n",
    "\n",
    "# Display findings\n",
    "for file_path, findings in findings_by_file.items():\n",
    "    print(f\"\\nüìÅ FILE: {os.path.basename(file_path)}\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    for i, finding in enumerate(findings, 1):\n",
    "        severity_icon = {\"CRITICAL\": \"üî¥\", \"HIGH\": \"üü†\", \"MEDIUM\": \"üü°\", \"LOW\": \"üü¢\"}\n",
    "        icon = severity_icon.get(finding['severity'], \"‚ö™\")\n",
    "        \n",
    "        print(f\"{i}. {icon} {finding['severity']} - {finding['type'].upper()}\")\n",
    "        print(f\"   üìç Line {finding['line']}: {finding['description']}\")\n",
    "        print(f\"   üìù Code: {finding['code'][:100]}{'...' if len(finding['code']) > 100 else ''}\")\n",
    "        if 'recommendation' in finding:\n",
    "            print(f\"   üí° Fix: {finding['recommendation']}\")\n",
    "        print()\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"üéØ SECURITY RECOMMENDATIONS:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Generate overall security recommendations\n",
    "if scan_results['total_vulnerabilities'] > 0:\n",
    "    print(f\"\"\"\n",
    "üîí IMMEDIATE ACTIONS REQUIRED:\n",
    "1. Address all CRITICAL vulnerabilities immediately\n",
    "2. Review and fix HIGH severity issues within 24-48 hours\n",
    "3. Plan remediation for MEDIUM severity issues\n",
    "4. Consider LOW severity issues for future security hardening\n",
    "\n",
    "üõ°Ô∏è SECURITY BEST PRACTICES:\n",
    "1. Use parameterized queries to prevent SQL injection\n",
    "2. Store secrets in environment variables, not hardcoded\n",
    "3. Use secure random generators from the 'secrets' module\n",
    "4. Implement proper input validation and sanitization\n",
    "5. Use strong cryptographic algorithms (SHA-256, AES-256)\n",
    "6. Add security headers and proper error handling\n",
    "7. Implement comprehensive logging for security events\n",
    "\"\"\")\n",
    "else:\n",
    "    print(\"‚úÖ No obvious vulnerabilities detected in the scanned code!\")\n",
    "    print(\"üîç Consider running additional security tests and penetration testing\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"‚úÖ Vulnerability assessment complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç ADVANCED SECURITY ANALYSIS\n",
      "============================================================\n",
      "üì¶ Scanning dependencies for known vulnerabilities...\n",
      "Error scanning dependencies: [Errno 2] No such file or directory: 'c:\\\\Users\\\\labadmin\\\\Documents\\\\repo\\\\KMSH_contracting\\\\requirements.txt'\n",
      "‚úÖ No obvious dependency vulnerabilities detected\n",
      "üìä Dependency Security Score: 5/10\n",
      "\n",
      "‚öôÔ∏è Scanning configuration files...\n",
      "Error analyzing .env: [openai:gpt-4o] completion error: API client not initialized.\n",
      "‚úÖ No obvious configuration security issues detected\n",
      "\n",
      "üìã GENERAL SECURITY RECOMMENDATIONS:\n",
      "\n",
      "============================================================\n",
      "üéØ NEXT STEPS FOR SECURITY HARDENING:\n",
      "============================================================\n",
      "\n",
      "1. üîÑ Regular Updates: Set up automated dependency updates\n",
      "2. üõ°Ô∏è Security Monitoring: Implement continuous security scanning\n",
      "3. üîê Secrets Management: Use proper secret management tools\n",
      "4. üìä Security Metrics: Track security debt and improvements\n",
      "5. üß™ Penetration Testing: Conduct regular security assessments\n",
      "6. üìö Security Training: Keep team updated on security best practices\n",
      "7. üö® Incident Response: Have a security incident response plan\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Advanced Dependency and Configuration Vulnerability Scanner\n",
    "class AdvancedSecurityScanner:\n",
    "    def __init__(self, client, model_name, api_provider):\n",
    "        self.client = client\n",
    "        self.model_name = model_name\n",
    "        self.api_provider = api_provider\n",
    "    \n",
    "    def scan_dependencies(self, requirements_file: str = None) -> Dict:\n",
    "        \"\"\"Scan dependencies for known vulnerabilities\"\"\"\n",
    "        if requirements_file is None:\n",
    "            requirements_file = os.path.join(project_root, \"requirements.txt\")\n",
    "        \n",
    "        vulnerabilities = []\n",
    "        \n",
    "        try:\n",
    "            with open(requirements_file, 'r') as f:\n",
    "                dependencies = f.readlines()\n",
    "            \n",
    "            # AI-powered dependency analysis\n",
    "            deps_text = '\\n'.join(dependencies)\n",
    "            prompt = f\"\"\"\n",
    "            You are a cybersecurity expert analyzing Python dependencies for known vulnerabilities.\n",
    "            \n",
    "            Dependencies:\n",
    "            {deps_text}\n",
    "            \n",
    "            For each dependency, check if there are known security vulnerabilities or if the version is outdated.\n",
    "            Consider:\n",
    "            1. Known CVEs (Common Vulnerabilities and Exposures)\n",
    "            2. Outdated versions with security patches available\n",
    "            3. Dependencies with history of security issues\n",
    "            4. Abandoned or unmaintained packages\n",
    "            \n",
    "            Respond with JSON:\n",
    "            {{\n",
    "                \"vulnerable_packages\": [\n",
    "                    {{\n",
    "                        \"package\": \"package_name\",\n",
    "                        \"current_version\": \"version\",\n",
    "                        \"vulnerability\": \"CVE-2023-xxxx or description\",\n",
    "                        \"severity\": \"CRITICAL|HIGH|MEDIUM|LOW\",\n",
    "                        \"recommended_action\": \"update to version X.X.X or replace with alternative\"\n",
    "                    }}\n",
    "                ],\n",
    "                \"security_score\": \"1-10\",\n",
    "                \"recommendations\": [\"list of general recommendations\"]\n",
    "            }}\n",
    "            \"\"\"\n",
    "            \n",
    "            response = get_completion(prompt, self.client, self.model_name, self.api_provider)\n",
    "            json_match = re.search(r'\\{.*\\}', response, re.DOTALL)\n",
    "            if json_match:\n",
    "                return json.loads(json_match.group(0))\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error scanning dependencies: {e}\")\n",
    "        \n",
    "        return {\"vulnerable_packages\": [], \"security_score\": \"5\", \"recommendations\": []}\n",
    "    \n",
    "    def scan_configuration_files(self) -> List[Dict]:\n",
    "        \"\"\"Scan configuration files for security issues\"\"\"\n",
    "        config_vulns = []\n",
    "        \n",
    "        # Check common configuration files\n",
    "        config_files = [\n",
    "            \"pyproject.toml\",\n",
    "            \"requirements.txt\", \n",
    "            \".env\",\n",
    "            \"config.py\",\n",
    "            \"settings.py\"\n",
    "        ]\n",
    "        \n",
    "        for config_file in config_files:\n",
    "            file_path = os.path.join(project_root, config_file)\n",
    "            if os.path.exists(file_path):\n",
    "                try:\n",
    "                    with open(file_path, 'r') as f:\n",
    "                        content = f.read()\n",
    "                    \n",
    "                    # AI analysis of configuration\n",
    "                    prompt = f\"\"\"\n",
    "                    Analyze this configuration file for security issues:\n",
    "                    \n",
    "                    File: {config_file}\n",
    "                    Content:\n",
    "                    {content[:2000]}  # Limit content size\n",
    "                    \n",
    "                    Look for:\n",
    "                    1. Hardcoded credentials or API keys\n",
    "                    2. Insecure default settings\n",
    "                    3. Debug mode enabled in production\n",
    "                    4. Overly permissive configurations\n",
    "                    5. Missing security headers or settings\n",
    "                    \n",
    "                    Respond with JSON:\n",
    "                    {{\n",
    "                        \"issues\": [\n",
    "                            {{\n",
    "                                \"type\": \"issue_type\",\n",
    "                                \"severity\": \"CRITICAL|HIGH|MEDIUM|LOW\",\n",
    "                                \"description\": \"description\",\n",
    "                                \"recommendation\": \"how to fix\"\n",
    "                            }}\n",
    "                        ]\n",
    "                    }}\n",
    "                    \"\"\"\n",
    "                    \n",
    "                    response = get_completion(prompt, self.client, self.model_name, self.api_provider)\n",
    "                    json_match = re.search(r'\\{.*\\}', response, re.DOTALL)\n",
    "                    if json_match:\n",
    "                        analysis = json.loads(json_match.group(0))\n",
    "                        for issue in analysis.get('issues', []):\n",
    "                            issue['file'] = config_file\n",
    "                            config_vulns.append(issue)\n",
    "                            \n",
    "                except Exception as e:\n",
    "                    print(f\"Error analyzing {config_file}: {e}\")\n",
    "        \n",
    "        return config_vulns\n",
    "\n",
    "# Ensure project_root is defined (in case setup cell wasn't run properly)\n",
    "if 'project_root' not in globals():\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "    print(f\"Setting project_root to: {project_root}\")\n",
    "\n",
    "# Run advanced security scanning\n",
    "advanced_scanner = AdvancedSecurityScanner(client, model_name, api_provider)\n",
    "\n",
    "print(\"\\nüîç ADVANCED SECURITY ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Dependency vulnerability scan\n",
    "print(\"üì¶ Scanning dependencies for known vulnerabilities...\")\n",
    "dep_results = advanced_scanner.scan_dependencies()\n",
    "\n",
    "if dep_results['vulnerable_packages']:\n",
    "    print(f\"\\nüö® VULNERABLE DEPENDENCIES FOUND:\")\n",
    "    for vuln in dep_results['vulnerable_packages']:\n",
    "        severity_icon = {\"CRITICAL\": \"üî¥\", \"HIGH\": \"üü†\", \"MEDIUM\": \"üü°\", \"LOW\": \"üü¢\"}\n",
    "        icon = severity_icon.get(vuln['severity'], \"‚ö™\")\n",
    "        print(f\"{icon} {vuln['package']} ({vuln.get('current_version', 'unknown version')})\")\n",
    "        print(f\"   üêõ Issue: {vuln['vulnerability']}\")\n",
    "        print(f\"   üí° Action: {vuln['recommended_action']}\")\n",
    "        print()\n",
    "else:\n",
    "    print(\"‚úÖ No obvious dependency vulnerabilities detected\")\n",
    "\n",
    "print(f\"üìä Dependency Security Score: {dep_results['security_score']}/10\")\n",
    "\n",
    "# Configuration file analysis\n",
    "print(\"\\n‚öôÔ∏è Scanning configuration files...\")\n",
    "config_vulns = advanced_scanner.scan_configuration_files()\n",
    "\n",
    "if config_vulns:\n",
    "    print(f\"\\nüö® CONFIGURATION ISSUES FOUND:\")\n",
    "    for issue in config_vulns:\n",
    "        severity_icon = {\"CRITICAL\": \"üî¥\", \"HIGH\": \"üü†\", \"MEDIUM\": \"üü°\", \"LOW\": \"üü¢\"}\n",
    "        icon = severity_icon.get(issue['severity'], \"‚ö™\")\n",
    "        print(f\"{icon} {issue['file']}: {issue['type']}\")\n",
    "        print(f\"   üìù {issue['description']}\")\n",
    "        print(f\"   üí° Fix: {issue['recommendation']}\")\n",
    "        print()\n",
    "else:\n",
    "    print(\"‚úÖ No obvious configuration security issues detected\")\n",
    "\n",
    "print(\"\\nüìã GENERAL SECURITY RECOMMENDATIONS:\")\n",
    "for rec in dep_results.get('recommendations', []):\n",
    "    print(f\"‚Ä¢ {rec}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üéØ NEXT STEPS FOR SECURITY HARDENING:\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\"\"\n",
    "1. üîÑ Regular Updates: Set up automated dependency updates\n",
    "2. üõ°Ô∏è Security Monitoring: Implement continuous security scanning\n",
    "3. üîê Secrets Management: Use proper secret management tools\n",
    "4. üìä Security Metrics: Track security debt and improvements\n",
    "5. üß™ Penetration Testing: Conduct regular security assessments\n",
    "6. üìö Security Training: Keep team updated on security best practices\n",
    "7. üö® Incident Response: Have a security incident response plan\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Generating comprehensive security review report...\n",
      "‚úÖ Security review report saved to: c:\\Users\\labadmin\\Documents\\repo\\KMSH_contracting\\security_review.md\n",
      "üìÑ Report contains 1350 words and 570 lines\n",
      "üìä Security review report successfully generated!\n",
      "üîó Location: c:\\Users\\labadmin\\Documents\\repo\\KMSH_contracting\\security_review.md\n",
      "üìã You can now review the comprehensive security assessment in Markdown format.\n"
     ]
    }
   ],
   "source": [
    "# Generate and Save Security Review Report\n",
    "def generate_security_report(scan_results, dep_results=None, config_vulns=None, output_file=\"security_review.md\"):\n",
    "    \"\"\"Generate a comprehensive security review report in Markdown format\"\"\"\n",
    "    \n",
    "    from datetime import datetime\n",
    "    import os\n",
    "    \n",
    "    # Ensure project_root is available - use global if exists, otherwise create it\n",
    "    global project_root\n",
    "    if 'project_root' not in globals() or project_root is None:\n",
    "        project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "        print(f\"Setting project_root to: {project_root}\")\n",
    "    \n",
    "    report_path = os.path.join(project_root, output_file)\n",
    "    \n",
    "    # Generate timestamp\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    \n",
    "    # Start building the markdown report\n",
    "    report = f\"\"\"# Security Vulnerability Assessment Report\n",
    "\n",
    "**Generated:** {timestamp}  \n",
    "**Scanner:** Software Vulnerability Assessment Agent  \n",
    "**Project:** KMSH_contracting  \n",
    "\n",
    "---\n",
    "\n",
    "## Executive Summary\n",
    "\n",
    "This report contains the results of an automated security vulnerability assessment performed on the KMSH_contracting codebase. The scan identified potential security weaknesses using pattern-based detection and security best practices.\n",
    "\n",
    "### Scan Overview\n",
    "- **Files Scanned:** {scan_results['scanned_files']}\n",
    "- **Total Vulnerabilities Found:** {scan_results['total_vulnerabilities']}\n",
    "- **Scan Type:** {\"AI-Enhanced + Pattern-Based\" if 'vuln_scanner' in globals() and vuln_scanner.ai_enabled else \"Pattern-Based Only\"}\n",
    "\n",
    "### Vulnerability Breakdown by Severity\n",
    "\"\"\"\n",
    "    \n",
    "    # Add severity breakdown\n",
    "    for severity in ['CRITICAL', 'HIGH', 'MEDIUM', 'LOW']:\n",
    "        count = scan_results['vulnerabilities_by_severity'][severity]\n",
    "        if count > 0:\n",
    "            icon = {'CRITICAL': 'üî¥', 'HIGH': 'üü†', 'MEDIUM': 'üü°', 'LOW': 'üü¢'}[severity]\n",
    "            report += f\"- **{severity}:** {count} {icon}\\n\"\n",
    "    \n",
    "    report += \"\\n---\\n\\n\"\n",
    "    \n",
    "    # Detailed Findings\n",
    "    if scan_results['detailed_findings']:\n",
    "        report += \"## Detailed Vulnerability Findings\\n\\n\"\n",
    "        \n",
    "        # Group findings by file\n",
    "        findings_by_file = {}\n",
    "        for finding in scan_results['detailed_findings']:\n",
    "            file_path = finding['file']\n",
    "            if file_path not in findings_by_file:\n",
    "                findings_by_file[file_path] = []\n",
    "            findings_by_file[file_path].append(finding)\n",
    "        \n",
    "        # Generate report for each file\n",
    "        for file_path, findings in findings_by_file.items():\n",
    "            filename = os.path.basename(file_path)\n",
    "            report += f\"### üìÅ {filename}\\n\\n\"\n",
    "            report += f\"**File Path:** `{file_path}`\\n\\n\"\n",
    "            \n",
    "            for i, finding in enumerate(findings, 1):\n",
    "                severity_icon = {'CRITICAL': 'üî¥', 'HIGH': 'üü†', 'MEDIUM': 'üü°', 'LOW': 'üü¢'}\n",
    "                icon = severity_icon.get(finding['severity'], '‚ö™')\n",
    "                \n",
    "                report += f\"#### {i}. {icon} {finding['severity']} - {finding['type'].replace('_', ' ').title()}\\n\\n\"\n",
    "                report += f\"**Description:** {finding['description']}\\n\\n\"\n",
    "                report += f\"**Location:** Line {finding['line']}\\n\\n\"\n",
    "                report += f\"**Code:**\\n```python\\n{finding['code']}\\n```\\n\\n\"\n",
    "                \n",
    "                if 'recommendation' in finding:\n",
    "                    report += f\"**Recommendation:** {finding['recommendation']}\\n\\n\"\n",
    "                \n",
    "                if 'match' in finding:\n",
    "                    report += f\"**Pattern Match:** `{finding['match']}`\\n\\n\"\n",
    "                \n",
    "                report += \"---\\n\\n\"\n",
    "    \n",
    "    else:\n",
    "        report += \"## ‚úÖ No Code Vulnerabilities Found\\n\\nNo obvious vulnerabilities were detected in the scanned Python files using pattern-based detection.\\n\\n\"\n",
    "    \n",
    "    # Dependency Analysis (if available)\n",
    "    if dep_results and dep_results.get('vulnerable_packages'):\n",
    "        report += \"## üì¶ Dependency Vulnerability Analysis\\n\\n\"\n",
    "        report += f\"**Security Score:** {dep_results['security_score']}/10\\n\\n\"\n",
    "        \n",
    "        for vuln in dep_results['vulnerable_packages']:\n",
    "            severity_icon = {'CRITICAL': 'üî¥', 'HIGH': 'üü†', 'MEDIUM': 'üü°', 'LOW': 'üü¢'}\n",
    "            icon = severity_icon.get(vuln['severity'], '‚ö™')\n",
    "            \n",
    "            report += f\"### {icon} {vuln['package']} - {vuln['severity']}\\n\\n\"\n",
    "            report += f\"**Current Version:** {vuln.get('current_version', 'Unknown')}\\n\\n\"\n",
    "            report += f\"**Vulnerability:** {vuln['vulnerability']}\\n\\n\"\n",
    "            report += f\"**Recommended Action:** {vuln['recommended_action']}\\n\\n\"\n",
    "            report += \"---\\n\\n\"\n",
    "    \n",
    "    # Configuration Issues (if available)\n",
    "    if config_vulns:\n",
    "        report += \"## ‚öôÔ∏è Configuration Security Issues\\n\\n\"\n",
    "        \n",
    "        for issue in config_vulns:\n",
    "            severity_icon = {'CRITICAL': 'üî¥', 'HIGH': 'üü†', 'MEDIUM': 'üü°', 'LOW': 'üü¢'}\n",
    "            icon = severity_icon.get(issue['severity'], '‚ö™')\n",
    "            \n",
    "            report += f\"### {icon} {issue['file']} - {issue['severity']}\\n\\n\"\n",
    "            report += f\"**Issue Type:** {issue['type']}\\n\\n\"\n",
    "            report += f\"**Description:** {issue['description']}\\n\\n\"\n",
    "            report += f\"**Recommendation:** {issue['recommendation']}\\n\\n\"\n",
    "            report += \"---\\n\\n\"\n",
    "    \n",
    "    # Security Recommendations\n",
    "    report += \"\"\"## üéØ Security Recommendations\n",
    "\n",
    "### Immediate Actions Required\n",
    "1. **Address CRITICAL vulnerabilities immediately** - These pose severe security risks\n",
    "2. **Fix HIGH severity issues within 24-48 hours** - These are significant security concerns\n",
    "3. **Plan remediation for MEDIUM severity issues** - Schedule fixes in upcoming sprints\n",
    "4. **Consider LOW severity issues for future hardening** - Include in technical debt backlog\n",
    "\n",
    "### Security Best Practices\n",
    "1. **Input Validation:** Implement proper input validation and sanitization\n",
    "2. **Secrets Management:** Store secrets in environment variables, not hardcoded\n",
    "3. **Secure Coding:** Use parameterized queries to prevent SQL injection\n",
    "4. **Cryptography:** Use strong cryptographic algorithms (SHA-256, AES-256)\n",
    "5. **Random Generation:** Use secure random generators from the 'secrets' module\n",
    "6. **Error Handling:** Implement proper error handling without exposing sensitive information\n",
    "7. **Security Headers:** Add appropriate security headers to web responses\n",
    "8. **Logging:** Implement comprehensive security event logging\n",
    "\n",
    "### Ongoing Security Measures\n",
    "1. **Regular Updates:** Set up automated dependency updates\n",
    "2. **Security Monitoring:** Implement continuous security scanning\n",
    "3. **Penetration Testing:** Conduct regular security assessments\n",
    "4. **Security Training:** Keep development team updated on security best practices\n",
    "5. **Incident Response:** Maintain a security incident response plan\n",
    "6. **Code Reviews:** Include security considerations in code review process\n",
    "7. **Security Metrics:** Track security debt and improvements over time\n",
    "\n",
    "---\n",
    "\n",
    "## Report Metadata\n",
    "\n",
    "**Scanner Version:** Software Vulnerability Assessment Agent v1.0  \n",
    "**Scan Method:** Pattern-based detection with regex matching  \n",
    "**File Types:** Python (.py) files  \n",
    "**Excluded:** Test files, __pycache__ directories  \n",
    "\n",
    "*This report was generated automatically. Manual security review is recommended for comprehensive assessment.*\n",
    "\"\"\"\n",
    "    \n",
    "    # Save the report\n",
    "    try:\n",
    "        with open(report_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(report)\n",
    "        print(f\"‚úÖ Security review report saved to: {report_path}\")\n",
    "        print(f\"üìÑ Report contains {len(report.split())} words and {len(report.splitlines())} lines\")\n",
    "        return report_path\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error saving report: {e}\")\n",
    "        return None\n",
    "\n",
    "# Ensure project_root is defined globally before running the report generator\n",
    "if 'project_root' not in globals():\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "    print(f\"Setting global project_root to: {project_root}\")\n",
    "\n",
    "# Generate and save the security report  \n",
    "print(\"üìù Generating comprehensive security review report...\")\n",
    "\n",
    "# Collect all scan data (use the results from previous scans)\n",
    "if 'scan_results' in globals():\n",
    "    # Get dependency and config results if they exist\n",
    "    dep_data = dep_results if 'dep_results' in globals() else None\n",
    "    config_data = config_vulns if 'config_vulns' in globals() else None\n",
    "    \n",
    "    # Generate the report\n",
    "    report_file = generate_security_report(\n",
    "        scan_results=scan_results,\n",
    "        dep_results=dep_data,\n",
    "        config_vulns=config_data,\n",
    "        output_file=\"security_review.md\"\n",
    "    )\n",
    "    \n",
    "    if report_file:\n",
    "        print(f\"üìä Security review report successfully generated!\")\n",
    "        print(f\"üîó Location: {report_file}\")\n",
    "        print(f\"üìã You can now review the comprehensive security assessment in Markdown format.\")\n",
    "    else:\n",
    "        print(\"‚ùå Failed to generate security report\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No scan results available. Please run the vulnerability scan first.\")\n",
    "    print(\"   Run the previous cells to generate scan_results, then run this cell again.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
