{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53e40e89",
   "metadata": {},
   "source": [
    "## Step 1: Documentation\n",
    "\n",
    "This initial block sets up our environment. It adds the project's root directory to the Python path, allowing us to import our custom `utils.py` script. We then initialize the connection to our Large Language Model (LLM).\n",
    "\n",
    "**Documentation:**\n",
    " - Product Requirements Document (PRD) generated from a high-level idea.\n",
    " - Architecture Decision Records (ADR) including auto-generated technical decisions with their justification\n",
    " - Architecture Document including auto-generated UML diagrams (e.g., Component or Sequence diagrams).\n",
    "\n",
    "\n",
    "**Model Selection:**\n",
    "Our `utils.py` script is configured to work with multiple AI providers. You can change the `model_name` parameter in the `setup_llm_client()` function to any of the models listed in the `RECOMMENDED_MODELS` dictionary in `utils.py`. For example, to use a Hugging Face model, you could change the line to: `client, model_name, api_provider = setup_llm_client(model_name=\"meta-llama/Llama-3.3-70B-Instruct\")`\n",
    "\n",
    "**Helper Functions Used:**\n",
    "- `setup_llm_client()`: To configure the API client for our chosen LLM.\n",
    "- `get_completion()`: To send a prompt to the LLM and get a response.\n",
    "- `save_artifact()`: To save our generated requirements to a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e102481a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-02 10:29:46,226 ag_aisoftdev.utils WARNING python-dotenv not installed; .env will not be loaded. provider=None model=None latency_ms=None artifacts_path=None\n",
      "2025-10-02 10:29:46,227 ag_aisoftdev.utils ERROR OPENAI_API_KEY not found in .env file. provider=openai model=gpt-4.1 latency_ms=None artifacts_path=None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************************************************\n",
      "Generating PRD for Contracting Visualization Software\n"
     ]
    },
    {
     "ename": "ProviderOperationError",
     "evalue": "[None:None] completion error: API client not initialized.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mProviderOperationError\u001b[39m                    Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 70\u001b[39m\n\u001b[32m     68\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m*\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m80\u001b[39m)\n\u001b[32m     69\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mGenerating PRD for\u001b[39m\u001b[33m\"\u001b[39m, app_name)\n\u001b[32m---> \u001b[39m\u001b[32m70\u001b[39m prd_from_template_output = \u001b[43mget_completion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprd_prompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mapi_provider\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     71\u001b[39m prd_from_template_output = clean_llm_output(prd_from_template_output)\n\u001b[32m     72\u001b[39m \u001b[38;5;28mprint\u001b[39m(prd_from_template_output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\labadmin\\Documents\\KMSH_contracting-3\\utils\\llm.py:110\u001b[39m, in \u001b[36mget_completion\u001b[39m\u001b[34m(prompt, client, model_name, api_provider, temperature)\u001b[39m\n\u001b[32m     94\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Fetch a text completion.\u001b[39;00m\n\u001b[32m     95\u001b[39m \n\u001b[32m     96\u001b[39m \u001b[33;03mRaises\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    107\u001b[39m \u001b[33;03m...     ...\u001b[39;00m\n\u001b[32m    108\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    109\u001b[39m prompt = normalize_prompt(prompt)\n\u001b[32m--> \u001b[39m\u001b[32m110\u001b[39m provider_module = \u001b[43mensure_provider\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mapi_provider\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompletion\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m provider_module.text_completion(client, prompt, model_name, temperature)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\labadmin\\Documents\\KMSH_contracting-3\\utils\\helpers.py:14\u001b[39m, in \u001b[36mensure_provider\u001b[39m\u001b[34m(client, api_provider, model_name, operation)\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Validate client and provider and return the provider module.\"\"\"\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m client:\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ProviderOperationError(\n\u001b[32m     15\u001b[39m         api_provider, model_name, operation, CLIENT_NOT_INITIALIZED\n\u001b[32m     16\u001b[39m     )\n\u001b[32m     17\u001b[39m provider_module = PROVIDERS.get(api_provider)\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m provider_module:\n",
      "\u001b[31mProviderOperationError\u001b[39m: [None:None] completion error: API client not initialized."
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "import tqdm as notebook_tqdm\n",
    "\n",
    "# Add the project's root directory to the Python path to ensure 'utils' can be imported.\n",
    "try:\n",
    "    # Assumes the notebook is in 'labs/Day_01_.../'\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
    "except IndexError:\n",
    "    # Fallback for different execution environments\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd()))\n",
    "\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "from utils import setup_llm_client, get_completion, save_artifact, clean_llm_output\n",
    "client, model_name, api_provider = setup_llm_client(model_name=\"gpt-4.1\")\n",
    "\n",
    "app_name=\"Contracting Visualization Software\"\n",
    "problem_statement = f\"\"\"\n",
    "Contracting Visualization Software is an AI-powered RESTful service application designed to help contracting companies.\n",
    "We need a tool that will do the following:\n",
    "1. View and explore historical data of contracts awarded by the US government through an insightful and\n",
    "    powerful dashboard with various visualizations.\n",
    "2. The application enables users to analyze trends, access contract details.\n",
    "3. Its primary focus is on data exploration, visualization, and reporting to support\n",
    "   strategicdecision-making based on awarded contract data.\n",
    "\"\"\"\n",
    "\n",
    "prd_prompt = f\"\"\"\n",
    "You are an expert AI-enabled product manager and enterprise architect.\n",
    "\n",
    "Your task is to create a comprehensive Product Requirements Document (PRD) based on the problem statement for the following system:\n",
    "\n",
    "Problem Statement: {problem_statement}\n",
    "System: \"{app_name}\"\n",
    "\n",
    "The PRD that includes:\n",
    "1. Executive Overview, Vision and Goals\n",
    "2. In-scope / Out-of-scope\n",
    "3. Personas\n",
    "4. Data Types: Contract Name, Company Awarded, Date Awarded, Location (where contract will be performed), Value of Contract, Length of Contract, Product or service information (NAICS and PSC categories) if available.\n",
    "5. User stories with story points and acceptance criteria: All acceptance criteria must be measurable and testable with HTTP codes, etc.\n",
    "6. Functional & non-functional requirements\n",
    "7. Goals and Success metrics\n",
    "8. Assumptions/constraints\n",
    "9. Error handling: Requirements include invalid input, server errors, etc.\n",
    "10. Dependencies\n",
    "11. Future considerations\n",
    "12. Milestones and timeline\n",
    "13. Security and compliance\n",
    "14. Error handling\n",
    "15. Glossary of terms\n",
    "16. Appendices\n",
    "17. References: sam.gov, GSA.gov, FPDS.gov\n",
    "\n",
    "Formatting requirements:\n",
    "- Use markdown formatting with appropriate headings and subheadings.\n",
    "- Include tables for personas and user stories.\n",
    "- Use bullet points for lists of requirements, goals, and other items.\n",
    "- Ensure clarity and conciseness in language.\n",
    "Make sure to cover all aspects of the system comprehensively.\n",
    "The PRD should be detailed and structured to guide the development team effectively.\n",
    "Use Markdown formatting with appropriate headings and subheadings.\n",
    "\"\"\"\n",
    "\n",
    "print(\"*\" * 80)\n",
    "print(\"Generating PRD for\", app_name)\n",
    "prd_from_template_output = get_completion(prd_prompt, client, model_name, api_provider)\n",
    "prd_from_template_output = clean_llm_output(prd_from_template_output)\n",
    "print(prd_from_template_output)\n",
    "if not prd_from_template_output:\n",
    "    raise ValueError(\"No PRD output generated\")\n",
    "else:\n",
    "    save_artifact(prd_from_template_output, \"artifacts/convisoft_prd.md\",overwrite=True)\n",
    "    print(\"PRD generated successfully, saving to artifacts...\")\n",
    "\n",
    "print(\"*\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "258981aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************************************************\n",
      "Generating ADR for GovWinSight\n",
      "# Architecture Decision Records (ADR): GovWinSight\n",
      "\n",
      "---\n",
      "\n",
      "## Table of Contents\n",
      "\n",
      "1. [Technical Decision Table](#technical-decision-table)\n",
      "2. [ADR-001: Framework Choice](#adr-001-framework-choice)\n",
      "3. [ADR-002: ML Model Baseline](#adr-002-ml-model-baseline)\n",
      "4. [ADR-003: Feature Engineering](#adr-003-feature-engineering)\n",
      "5. [ADR-004: Database Selection](#adr-004-database-selection)\n",
      "6. [ADR-005: Security Architecture](#adr-005-security-architecture)\n",
      "7. [ADR-006: Observability (Logging, Monitoring, Audit)](#adr-006-observability-logging-monitoring-audit)\n",
      "8. [ADR-007: Model Transparency & Explainability](#adr-007-model-transparency--explainability)\n",
      "9. [ADR-008: Awards API Design](#adr-008-awards-api-design)\n",
      "\n",
      "---\n",
      "\n",
      "## Technical Decision Table\n",
      "\n",
      "| Rule                                   | Signal                                                                            | Decision                                                                                                 | Justification                                                                                                   |\n",
      "|-----------------------------------------|-----------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------|\n",
      "| Framework must be modern, secure, and cloud-ready | RESTful API, dashboard, scalability, FedRAMP requirement                           | Python FastAPI for API; React for dashboard                                                              | FastAPI is performant, secure, async; React is best-practice for modern dashboards; both have FedRAMP precedent |\n",
      "| ML models must be interpretable and accurate | Predict bid/win probabilities (≥80% AUC), actionable recommendations, explainable  | scikit-learn (Random Forest, XGBoost baseline), with SHAP for explainability                             | SOTA tabular ML, high interpretability, rapid prototyping, compliance friendly                                  |\n",
      "| Database must support structured, analytical, and audit data | Relational data, analytics, audit, compliance                                      | AWS RDS PostgreSQL                                                                                       | ACID compliance, FedRAMP, supports analytics, audit, and PII masking                                             |\n",
      "| Feature engineering must be robust, auditable, and reproducible | Historical contract data, vendor features, auditability                             | Feature pipelines via Pandas, dbt, and data versioning                                                   | Supports reproducibility, transparency, and regulatory audit requirements                                        |\n",
      "| Security must be FISMA/FedRAMP compliant | Cloud, RBAC, encryption, audit, SSO                                                | OAuth2/SSO, AWS KMS encryption, RBAC, TLS 1.2+, no PII storage                                           | Meets all regulatory requirements, least-privilege, supports vendor SSO                                          |\n",
      "| Observability must support audit, compliance, and debugging | Uptime, audit trails, error logging, monitoring                                    | Datadog (APM), AWS CloudWatch, centralized structured logs, correlation IDs                               | Comprehensive, FedRAMP authorized, supports audit and rapid incident response                                   |\n",
      "| Model transparency is required for recommendations | Actionable insights, explainability, accuracy reporting                            | SHAP values in API/dashboard, model performance exposed                                                  | Meets transparency, user trust, and compliance standards                                                        |\n",
      "| API must be RESTful, secure, and fast   | REST-only (MVP), <2s 95th percentile, error handling, versioned endpoints          | RESTful JSON APIs, OpenAPI 3.0 docs, 2s p95 SLA, error codes/messages, correlation IDs                   | Alignment with PRD, best-practice usability, supportability, and compliance                                     |\n",
      "\n",
      "---\n",
      "\n",
      "## ADR-001: Framework Choice\n",
      "\n",
      "### Context\n",
      "GovWinSight must expose scalable, secure RESTful APIs and provide a modern vendor-facing dashboard. Requirements include:\n",
      "- Fast API response times (<2s, 95th percentile)\n",
      "- FedRAMP/FISMA compliance\n",
      "- Cloud-native deployment (AWS GovCloud)\n",
      "- Modern, intuitive dashboard\n",
      "- Role-based access and SSO support\n",
      "\n",
      "### Decision\n",
      "- **API Framework:** Python [FastAPI](https://fastapi.tiangolo.com/)\n",
      "- **Dashboard:** React (with Plotly for analytics visualizations)\n",
      "- **API Documentation:** OpenAPI 3.0 (auto-generated by FastAPI)\n",
      "- **Deployment:** Dockerized microservices on AWS GovCloud (ECS or EKS)\n",
      "- **Authentication:** OAuth2.0/SSO integration\n",
      "\n",
      "### Status\n",
      "**Accepted** (for MVP and foreseeable roadmap)\n",
      "\n",
      "### Consequences\n",
      "- Enables rapid, type-safe API development and highly performant async endpoints.\n",
      "- React enables rich dashboards, rapid iteration, and strong open-source/component support.\n",
      "- Both frameworks have large ecosystems and FedRAMP precedents.\n",
      "- Lower learning curve for hiring and onboarding.\n",
      "\n",
      "### Justification\n",
      "- FastAPI is asynchronous, performant, and designed for modern RESTful APIs.\n",
      "- React is the de facto standard for data-driven dashboards.\n",
      "- Both integrate well with AWS GovCloud and security toolchains.\n",
      "\n",
      "### Alternatives Considered\n",
      "- Django/Flask (slower, less async)\n",
      "- Angular/Vue (less adoption for data dashboards in this sector)\n",
      "- Java/Spring Boot (higher complexity, slower iteration)\n",
      "\n",
      "---\n",
      "\n",
      "## ADR-002: ML Model Baseline\n",
      "\n",
      "### Context\n",
      "The system must provide accurate predictions of bid and win probabilities (≥80% AUC) and actionable recommendations. Key requirements:\n",
      "- Interpretability (for recommendations and compliance)\n",
      "- Rapid iteration and retraining\n",
      "- Ability to handle tabular, structured data\n",
      "\n",
      "### Decision\n",
      "- **Baseline Models:** Random Forest and XGBoost (scikit-learn, XGBoost)\n",
      "- **Explainability:** SHAP values for model interpretation and feature attribution\n",
      "- **Pipeline:** Modular ML pipeline using scikit-learn, pandas, joblib for serialization\n",
      "\n",
      "### Status\n",
      "**Accepted** (for MVP, to be revisited as data grows)\n",
      "\n",
      "### Consequences\n",
      "- State-of-the-art performance on tabular data\n",
      "- High interpretability via SHAP for actionable recommendations\n",
      "- Easy retraining and reproducibility\n",
      "- Supports compliance (explanation of predictions)\n",
      "\n",
      "### Justification\n",
      "- Random Forest/XGBoost are industry standards for tabular, structured prediction tasks.\n",
      "- SHAP is widely accepted for explainability and is supported by both models.\n",
      "- scikit-learn and XGBoost are FedRAMP compatible (Python, open-source).\n",
      "\n",
      "### Alternatives Considered\n",
      "- Deep learning (overkill, less interpretable)\n",
      "- Linear models (potentially underfitting)\n",
      "- Automated ML platforms (vendor lock-in, less transparency)\n",
      "\n",
      "---\n",
      "\n",
      "## ADR-003: Feature Engineering\n",
      "\n",
      "### Context\n",
      "Features must be robust, auditable, and reproducible, supporting regulatory requirements and accurate ML predictions. Data sources include FPDS, SAM, and vendor-supplied data.\n",
      "\n",
      "### Decision\n",
      "- **Feature Pipeline:** pandas + dbt (for SQL-based transformations and versioning)\n",
      "- **Data Versioning:** DVC or MLflow for tracking feature versions and data lineage\n",
      "- **Auditing:** All feature transformations documented and code-reviewed\n",
      "- **Storage:** Centralized feature store (PostgreSQL or S3 + Parquet for large features)\n",
      "\n",
      "### Status\n",
      "**Accepted**\n",
      "\n",
      "### Consequences\n",
      "- Ensures reproducibility and traceability for compliance\n",
      "- Facilitates debugging of model drift or data issues\n",
      "- Supports data science and engineering collaboration\n",
      "\n",
      "### Justification\n",
      "- dbt is industry standard for data transformation versioning in analytics\n",
      "- pandas is flexible for complex feature engineering in Python ML pipelines\n",
      "- Feature versioning supports auditability and rollback\n",
      "\n",
      "### Alternatives Considered\n",
      "- Custom ETL scripts (less reproducible)\n",
      "- Proprietary feature stores (cost, vendor lock-in)\n",
      "\n",
      "---\n",
      "\n",
      "## ADR-004: Database Selection\n",
      "\n",
      "### Context\n",
      "GovWinSight requires:\n",
      "- Structured data for solicitations, vendors, analytics\n",
      "- Audit trails\n",
      "- Scalability and compliance with FISMA/FedRAMP\n",
      "- Support for analytics queries and dashboarding\n",
      "\n",
      "### Decision\n",
      "- **Primary Database:** AWS RDS PostgreSQL (FedRAMP authorized)\n",
      "- **Analytical Layer:** PostgreSQL analytical extensions (or Redshift for scale-out analytics if needed)\n",
      "- **Audit Trails:** Append-only audit tables within PostgreSQL\n",
      "\n",
      "### Status\n",
      "**Accepted**\n",
      "\n",
      "### Consequences\n",
      "- ACID compliance, transactional safety\n",
      "- Supports complex queries, analytics, and reporting\n",
      "- Native support in AWS GovCloud\n",
      "- Audit-friendly (native logging, triggers)\n",
      "\n",
      "### Justification\n",
      "- PostgreSQL is robust, widely used in government, and supports compliance requirements\n",
      "- AWS RDS provides managed backups, scaling, and encryption at rest\n",
      "\n",
      "### Alternatives Considered\n",
      "- NoSQL (overkill for current needs, less audit-friendly)\n",
      "- MongoDB (less fit for relational, audit-heavy scenarios)\n",
      "- Azure SQL (secondary, only if Azure GovCloud selected)\n",
      "\n",
      "---\n",
      "\n",
      "## ADR-005: Security Architecture\n",
      "\n",
      "### Context\n",
      "System must adhere to FISMA/FedRAMP, enforce RBAC, encrypt data, and ensure secure authentication and audit.\n",
      "\n",
      "### Decision\n",
      "- **Authentication:** OAuth 2.0 with SSO (SAML/OpenID Connect, e.g., Okta, Azure AD)\n",
      "- **Authorization:** RBAC enforced at API and dashboard\n",
      "- **Encryption:** TLS 1.2+ for all transit; AWS KMS for storage encryption\n",
      "- **PII:** No storage of sensitive PII; data anonymization where required\n",
      "- **Audit:** All user/admin actions logged and stored securely\n",
      "- **Compliance:** Regular scans, annual penetration testing, compliance checklists enforced\n",
      "\n",
      "### Status\n",
      "**Accepted**\n",
      "\n",
      "### Consequences\n",
      "- Meets all regulatory security requirements\n",
      "- Supports vendor SSO/enterprise login\n",
      "- Minimizes risk of data breaches or non-compliance\n",
      "\n",
      "### Justification\n",
      "- OAuth2/SSO is industry standard and required for enterprise/Gov\n",
      "- RBAC enforces least-privilege access\n",
      "- Encryption and audit are mandatory per PRD\n",
      "\n",
      "### Alternatives Considered\n",
      "- Custom authentication (non-compliant, higher risk)\n",
      "- Local-only user management (no SSO, not scalable)\n",
      "\n",
      "---\n",
      "\n",
      "## ADR-006: Observability (Logging, Monitoring, Audit)\n",
      "\n",
      "### Context\n",
      "Uptime, reliability, and compliance require robust logging, monitoring, and audit trails.\n",
      "\n",
      "### Decision\n",
      "- **Monitoring:** AWS CloudWatch (infrastructure), Datadog (APM, logs, dashboards)\n",
      "- **Logging:** Centralized, structured logs with correlation IDs for all requests/errors\n",
      "- **Audit:** Append-only audit logs (user/admin actions) with retention per compliance policy\n",
      "- **Alerting:** Automated alerts for SLA breaches, security events\n",
      "\n",
      "### Status\n",
      "**Accepted**\n",
      "\n",
      "### Consequences\n",
      "- Enables rapid incident response and root-cause analysis\n",
      "- Satisfies compliance for audit trails and monitoring\n",
      "- Supports performance and reliability SLAs\n",
      "\n",
      "### Justification\n",
      "- CloudWatch and Datadog are FedRAMP authorized, integrate with cloud-native stack\n",
      "- Centralized logs with correlation IDs streamline support and debugging\n",
      "\n",
      "### Alternatives Considered\n",
      "- Self-hosted ELK stack (higher overhead, less compliant)\n",
      "- No monitoring (unacceptable for compliance and reliability)\n",
      "\n",
      "---\n",
      "\n",
      "## ADR-007: Model Transparency & Explainability\n",
      "\n",
      "### Context\n",
      "Users must understand model predictions and recommendations; transparency is required for trust and compliance.\n",
      "\n",
      "### Decision\n",
      "- **Feature Attribution:** SHAP values calculated for each prediction\n",
      "- **API/Dashboard:** Expose top contributing features and explanations with each result\n",
      "- **Performance Reporting:** Dashboard shows model performance (AUC, last retrain date)\n",
      "- **Documentation:** Model methodology and limitations documented for users\n",
      "\n",
      "### Status\n",
      "**Accepted**\n",
      "\n",
      "### Consequences\n",
      "- Users can see \"why\" a prediction/recommendation was made\n",
      "- Increases trust in system outputs\n",
      "- Meets compliance and best-practice recommendations\n",
      "\n",
      "### Justification\n",
      "- SHAP is the standard for feature attribution in ML\n",
      "- Model performance and transparency are key success metrics in PRD\n",
      "\n",
      "### Alternatives Considered\n",
      "- No explainability (not compliant, reduces user trust)\n",
      "- Custom explanations (harder to maintain, less robust)\n",
      "\n",
      "---\n",
      "\n",
      "## ADR-008: Awards API Design\n",
      "\n",
      "### Context\n",
      "APIs should be RESTful, versioned, secure, and usable by vendor data scientists and business users. Error handling and documentation must be robust.\n",
      "\n",
      "### Decision\n",
      "- **Design:** RESTful JSON APIs, versioned (`/api/v1/`)\n",
      "- **Documentation:** OpenAPI 3.0, auto-generated, with code samples\n",
      "- **Endpoints:** As per PRD (`/predict/bid-probability`, `/predict/win-probability`, etc.)\n",
      "- **Error Handling:** Standardized error codes/messages, correlation IDs, 4xx/5xx per spec\n",
      "- **Performance:** <2s response time (95th percentile)\n",
      "- **Security:** OAuth2.0 bearer tokens, RBAC per endpoint\n",
      "- **Rate Limiting:** 429 responses with retry-after headers\n",
      "\n",
      "### Status\n",
      "**Accepted**\n",
      "\n",
      "### Consequences\n",
      "- Predictable, standards-compliant API design\n",
      "- Smooth integration for vendor data scientists and business apps\n",
      "- Supports audit and compliance, simplifies troubleshooting\n",
      "\n",
      "### Justification\n",
      "- RESTful APIs are the industry and government standard for interoperability\n",
      "- Error and rate-limiting design aligns with PRD and best practices\n",
      "\n",
      "### Alternatives Considered\n",
      "- Non-RESTful APIs (GraphQL, SOAP - out of scope per PRD)\n",
      "- Unversioned APIs (not maintainable)\n",
      "- Weak error handling (would not meet requirements)\n",
      "\n",
      "---\n",
      "\n",
      "# Summary\n",
      "\n",
      "These ADRs provide a comprehensive, PRD-aligned architectural blueprint for GovWinSight. They ensure:\n",
      "- Regulatory compliance and security\n",
      "- Modern, scalable, and maintainable technology choices\n",
      "- Transparency and trust in ML-driven recommendations\n",
      "- High usability for both business and technical users\n",
      "\n",
      "---\n",
      "\n",
      "## Personas Table\n",
      "\n",
      "| Persona Name      | Role                  | Goals                                                | Pain Points                                      |\n",
      "|-------------------|----------------------|------------------------------------------------------|--------------------------------------------------|\n",
      "| Contract Analyst  | Vendor employee      | Identify best opportunities, improve win rate        | Manual research, lack of actionable insights      |\n",
      "| Capture Manager   | Vendor executive     | Strategize on bids, maximize ROI                     | Difficulty prioritizing bids, unpredictable wins  |\n",
      "| Data Scientist    | Vendor technical     | Integrate predictions with internal tools            | Poor API documentation, limited data access       |\n",
      "| GovWinSight Admin | Internal operator    | Monitor system, manage users/data, ensure compliance | System downtime, access issues, data integrity    |\n",
      "\n",
      "---\n",
      "\n",
      "## User Stories Table\n",
      "\n",
      "| ID  | Persona           | User Story                                                                                              | Story Points | Acceptance Criteria                                                                                               |\n",
      "|-----|-------------------|--------------------------------------------------------------------------------------------------------|--------------|-------------------------------------------------------------------------------------------------------------------|\n",
      "| US1 | Contract Analyst  | As a contract analyst, I want to see the likelihood of our company bidding on a solicitation so I can prioritize opportunities. | 5            | - API returns probability (0-1) with 200 OK <br> - Invalid solicitation ID returns 400 Bad Request                |\n",
      "| US2 | Capture Manager   | As a capture manager, I want to see the vendor most likely to win a solicitation so we can understand our position. | 8            | - API returns vendor name & win probability with 200 OK <br> - Non-existent solicitation returns 404 Not Found    |\n",
      "| US3 | Contract Analyst  | As a contract analyst, I want actionable recommendations to improve our win probability.                 | 8            | - Dashboard displays at least 3 actionable recommendations <br> - API returns 200 OK with recommendations array   |\n",
      "| US4 | Data Scientist    | As a data scientist, I want to programmatically retrieve predictions via REST API for integration.       | 5            | - API endpoints are documented <br> - All endpoints respond within 2 seconds (95th percentile)                    |\n",
      "| US5 | Contract Analyst  | As a contract analyst, I want to view all predictions and analytics in a user-friendly dashboard.        | 13           | - Dashboard loads within 3 seconds <br> - All insights available via navigation <br> - 200 OK for all endpoints   |\n",
      "| US6 | Admin             | As an admin, I want to manage user accounts and monitor system health.                                  | 8            | - Admin actions (create, disable user) return 200 OK <br> - Monitoring dashboard loads within 2 seconds           |\n",
      "\n",
      "---\n",
      "\n",
      "# End of GovWinSight Architecture Decision Record (ADR) Set\n",
      "ADR generated successfully, saving to artifacts...\n",
      "********************************************************************************\n"
     ]
    }
   ],
   "source": [
    "# Create the Architecture Decision Records (ADR)\n",
    "from utils import load_artifact, render_plantuml_diagram\n",
    "prd_md_artifact=load_artifact(\"artifacts/govwinsight2_prd.md\")\n",
    "\n",
    "app_description=f\"\"\"\n",
    "GovWinSight is an AI-powered RESTFul service application designed to help contracting companies improve their win \n",
    "rates on federal solicitations. The system leverages historical contracting data and advanced machine\n",
    "learning models to provide actionable insights and predictions.\n",
    "\"\"\"\n",
    "\n",
    "adr_prompt = f\"\"\"\n",
    "You are an expert software architect.\n",
    "\n",
    "Your task is to create a set of Architercture Decision Record based on the PRD for the following system:\n",
    "\n",
    "System PRD: {prd_md_artifact}\n",
    "System: {app_name}\n",
    "System Description: {app_description}\n",
    "\n",
    "The ADR includes:\n",
    "•\tContext, decision, status, consequences, justification, and alternatives for each ADR\n",
    "•\tAt minimum, cover:\n",
    "      - Framework choice\n",
    "      - ML model baseline\n",
    "      - Feature engineering\n",
    "      - Database\n",
    "      - Security\n",
    "      - Observability\n",
    "      - Model transparency\n",
    "      - Awards API design\n",
    "Ensure it strictly aglined to the PRD.\n",
    "Also include an auto-generated technical decision table with the format:\n",
    "Rule → Signal → Decision → Justification\n",
    "\n",
    "Formatting requirements:\n",
    "- Use markdown formatting with appropriate headings and subheadings.\n",
    "- Include tables for personas and user stories.\n",
    "- Use bullet points for lists of requirements, goals, and other items.\n",
    "- Ensure clarity and conciseness in language.\n",
    "Make sure to cover all aspects of the system comprehensively.\n",
    "The ADR should be detailed and structured to guide the development team effectively.\n",
    "Use Markdown formatting with appropriate headings and subheadings.\n",
    "\"\"\"\n",
    "\n",
    "print(\"*\" * 80)\n",
    "print(\"Generating ADR for\", app_name)\n",
    "adr_from_template_output = get_completion(adr_prompt, client, model_name, api_provider)\n",
    "adr_from_template_output = clean_llm_output(adr_from_template_output)\n",
    "print(adr_from_template_output)\n",
    "if not adr_from_template_output:\n",
    "    raise ValueError(\"No ADR output generated\")\n",
    "else:\n",
    "    save_artifact(adr_from_template_output, \"artifacts/govwinsight2_adr.md\", overwrite=True)\n",
    "    print(\"ADR generated successfully, saving to artifacts...\")\n",
    "\n",
    "print(\"*\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d12d189",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "28cd8517",
   "metadata": {},
   "source": [
    "## Step 2: Backend\n",
    "\n",
    "Complete the following challenges in order. Each one builds upon the last, increasing in technical complexity and value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c114cb",
   "metadata": {},
   "source": [
    "### Challenge 1 (Foundational): Brainstorming Features\n",
    "\n",
    "**Task:** Use the LLM to brainstorm a list of potential features and user personas based on the problem statement.\n",
    "\n",
    "**Instructions:**\n",
    "1. Write a simple prompt that asks the LLM to brainstorm features for the onboarding tool.\n",
    "2. Write a second prompt to identify three distinct user personas who would use this tool.\n",
    "3. Run both prompts and review the markdown output.\n",
    "\n",
    "**Expected Quality:** The output should be a simple, readable markdown list of features and a description of the personas. This is a good first step but lacks the structure needed for automation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84c956c",
   "metadata": {},
   "source": [
    "### Challenge 2 (Intermediate): Generating Formal User Stories\n",
    "\n",
    "**Task:** Now, let's increase the value by generating structured, formal Agile User Stories.\n",
    "\n",
    "**Instructions:**\n",
    "1. Create a new, more sophisticated prompt.\n",
    "2. This prompt should instruct the LLM to act as a Senior Product Manager.\n",
    "3. It must use the brainstormed features and personas from the previous step as context.\n",
    "4. The key instruction is to generate a list of user stories, each with detailed acceptance criteria in Gherkin format (`Given/When/Then`).\n",
    "5. **Crucially, the prompt must demand the final output be a well-formed JSON array of objects.** Each object should represent a user story and have keys like `id`, `user_story`, `persona`, and `acceptance_criteria`.\n",
    "\n",
    "> **Tip:** If the LLM's output isn't perfect JSON, try making your prompt even more specific. You can tell it, 'Do not include any text before or after the JSON array. Your response must begin with [ and end with ].'\n",
    "\n",
    "**Expected Quality:** The output should not be markdown, but a clean, parsable JSON string. This is a significant step up in value, as a JSON artifact can be automatically processed by other systems (e.g., imported into Jira)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc29224",
   "metadata": {},
   "source": [
    "### Challenge 3 (Advanced): Programmatic Validation and Artifact Creation\n",
    "\n",
    "**Task:** Now for the highest-value step. Instead of just looking at the JSON, we will programmatically validate it and save it as a formal project artifact. This ensures reliability and prepares the requirements for automated use in later stages of the SDLC.\n",
    "\n",
    "**Instructions:**\n",
    "1. Complete the `validate_and_save_stories` function below.\n",
    "2. The function should iterate through the list of stories.\n",
    "3. For each story, it must validate that the required keys are present and that the acceptance criteria list is not empty.\n",
    "4. If all stories are valid, it should save the data to `artifacts/day1_user_stories.json`.\n",
    "\n",
    "**Expected Quality:** A robust script that guarantees the integrity of our requirements artifact. The final output is a validated `day1_user_stories.json` file in the `artifacts` directory, ready to be used as a reliable input for Day 2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53390e28",
   "metadata": {},
   "source": [
    "## Lab Conclusion\n",
    "\n",
    "Congratulations! You have completed the first lab. You started with a vague, one-sentence problem and finished with a structured, validated, machine-readable requirements artifact. This is the critical first step in an AI-assisted software development lifecycle. The `day1_user_stories.json` file you created will be the direct input for our next lab, where we will generate a formal Product Requirements Document (PRD).\n",
    "\n",
    "> **Key Takeaway:** The single most important skill demonstrated in this lab is turning unstructured ideas into structured, machine-readable data (JSON). This transformation is what enables automation and integration with other tools later in the SDLC."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
